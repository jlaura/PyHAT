{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening & Accessing Kaguya Spectral Profiler Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it is necessary to import the `libpyhat` module.  This notebook also imports a helper function `get_path` that makes working with the sample data shipped with `libpyhat` easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpyhat as phat\n",
    "from libpyhat.examples import get_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open a spectral profiler 'image', we use the `phat/Spectra.from_spectral_profiler` call.  If example data is not going to be used, the `get_path(<my_file_path>)` can be replaced with `<my_file_path>`, since our helper function does not know where your data is being stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Spectra' has no attribute 'from_spectral_profiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ff81dbb38a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpectra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spectral_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SP_2C_02_02358_S138_E3586.spc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Spectra' has no attribute 'from_spectral_profiler'"
     ]
    }
   ],
   "source": [
    "s = phat.Spectra.from_spectral_profiler(get_path('SP_2C_02_02358_S138_E3586.spc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `s` object is based on a pandas data frame.  Therefore, anything that you might normally do with a pandas data frame, can be applied the the `libpyhat.Spectra` object.  In this notebook we demo a few of the possible operations that Pandas provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the data\n",
    "\n",
    "To see the first or last rows in the `Spectra` object, one can use `head` or `tail`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the data at the observation level\n",
    "\n",
    "Above, the data is viewed as if each row is a different observational unit.  In reality, each observation is composed of four rows:  (1) a team provided quality assurance row (QA), (2) the raw observered spectra (RAW), (3) a mare corrected continuum (REF1), and (4) a highlands corrected continuum (REF2).  If we want to work with each observation, we can group by the `id` and then loop over the observations like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgroups = s.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations do we have?\n",
    "len(sgroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is possible to access each group by key.  In the case of spectral profiler, these keys are simply autoincrementing integers (0, 1, 2, ..., n).  The cell above (`len(sgroup)`), shows that this file contains 38 observations keyed 0 - 37. Below, we access the first group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs0 = sgroups.get_group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see just the metadata for this observation, we can access the `meta` attribute like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs0.meta.head(4)\n",
    "# obs0.meta is the correct call - I am using `.head(4)` because of a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, it is possible to access just the observed information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obs0.spectra.head(4)\n",
    "# obs0.spectra is the correct call - I am using `.head(4)` because of a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying for data of interest\n",
    "\n",
    "Since the `Spectra` object is a pandas data frame, it is possible to perform SQL style queries on any fields. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = s.query('INCIDENCE_ANGLE < 30 & CENTER_LATITUDE < -14')\n",
    "len(subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing a subset of the spectral data by label\n",
    "\n",
    "The columns of the `Spectra` object are labeled by wavelength.  Notice how, in the above cell, some of the wavelength lables have many trailing zeros (or .00000000000004).  We are seeing floating point precision issues that would normally make label based access a pain.  Who really wants to type all of those zeros?  For that reason, the `Spectra` object supports the idea of `tolerance`.  The user can supply a wavelength value within the `tolerance` and we round under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the tolerance value?\n",
    "s.tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .get to only get the rows labeled 'REF1' and then get the wavelength (if one exists) within the tolerance of 511.7\n",
    "s.get['REF1'][511.7].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.tolerance = 0.1\n",
    "# This should result in an error, because 511.7 plus or minus 0.1 is not an available wavelength.  We wrapped this in a try/except block to keep a nasty looking stack trace out of the tutorial.\n",
    "try:\n",
    "    s.get['REF1'][511.7].head(5)\n",
    "except:\n",
    "    print('Key Error: 511.7 is not in the index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to access a range of values in a similar manner.  For example, if we only want to work with data around the 1um absorption band.  \n",
    "\n",
    "The syntax for grabbing the subset is called a slice.  In the first position we have the label of the rows that we want to grab, e.g., `REF1`.  In the second position we use a `:` to indicate that we want to grab everything and in the third position we use `start:stop` notation to indicate that all wavelengths between 700 and 1600 should be selected.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = s.get['REF1', :, 700:1600]\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Conversion\n",
    "Finally, it is possible to convert from a `libpysat` Spectra object into any number of formats support by Pandas.  For example, below, we convert the `.spc` file into CSV that can be opened and worked with in Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv('SP_2C_02_02358_S138_E3586.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 SP_2C_02_02358_S138_E3586.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
